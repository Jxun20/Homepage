<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Xun Jiang</title>
  
  <meta name="author" content="Xun Jiang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="image/favicon.ico">
</head>

  <body>
  <table width="950" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Xun Jiang &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
		  </name>
        </p>

        <p align=center>
          <a href="https://scholar.google.com/citations?user=oAjQIUEAAAAJ">Google Scholar</a>
          &nbsp/&nbsp
          <a href="https://github.com/CFM-MSG/">Github&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a> 
        </p>
		<p> I am a first-year Ph.D student in Successive Postgraduate and Doctoral Program at <a href="http://cfm.uestc.edu.cn">CFM lab</a> of the University of Electronic and Science of China (UESTC), supervised by <a href="https://cfm.uestc.edu.cn/~shenht/">Prof. Heng Tao Shen</a>, co-supervised by <a href="https://cfm.uestc.edu.cn/~fshen/">Prof. Fumin Shen</a> and <a href="https://interxuxing.github.io/">Prof. Xing Xu</a>. Before that, I obtained my bachelor degree in Department of Software Engineering from UESTC in 2020 and was awarded as Honor Graduates of UESTC. I also won the Best Student Paper in ICME 2022. 
		</p>

    <p> My research interests include but are not limited to Multimedia Retrieval, Multimodal Learning, Long-term Video Understanding, and Weakly-Supervised Learning.  
    </p>

    <p>I am always glad to academic exchange, please feel free to contact me if you are interested in my research topic. Email: xun_jiang@outlook.com 
    </p>




        </td>
        <td width="33%">
        <img src="image/xun_jiang.png" width="210">
        </td>
      </tr>
      </table>


<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>News</heading>
          <p>
		  <li> <strongsmall>[2023/03]</strongsmall> &nbsp;&nbsp;<smalll>1 paper about cross-modal untrimmed video retrieval is accepted by ICME 2023!</smalll><br/>
      <li> <strongsmall>[2022/09]</strongsmall> &nbsp;&nbsp;<smalll>1 paper about video content retrieval is accepted by TNNLS!</smalll><br/>
		  <li> <strongsmall>[2022/06]</strongsmall> &nbsp;&nbsp;<smalll>Received 2022 ICME Best Student Paper Award!</smalll><br/>
      <li> <strongsmall>[2022/06]</strongsmall> &nbsp;&nbsp;<smalll>1 paper about audible video content parsing is accepted by ACM MM 2022!</smalll><br/>
		  <li> <strongsmall>[2022/03]</strongsmall> &nbsp;&nbsp;<smalll>1 paper about video paragraph grounding is accepted by ICME 2022!</smalll><br/>
		  <li> <strongsmall>[2022/03]</strongsmall> &nbsp;&nbsp;<smalll>1 paper about semi-supervised video content understanding is accepted by CVPR 2022!</smalll><br/>
          </p>
        </td>
      </tr>
</table>




      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Education</heading>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        

        <tr>
          <td width="10%">
            <img src='image/uestc_icon.jpg' width="100">
          </td>

        <td width="75%" valign="middle">
          <p>
          <stronghuge>University of Electronic Science and Technology of China (UESTC), China</stronghuge><br />
          Ph.D. in Computer Science and Technology &nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2020 - Present <br />
          In Successive Postgraduate and Doctoral Program
          </p>
        </td>
        </tr>



        <tr>
          <td width="10%">
            <img src='image/uestc_icon.jpg' width="100">
          </td>

        <td width="75%" valign="middle">
          <p>
          <stronghuge>University of Electronic Science and Technology of China (UESTC), China</stronghuge><br />
          Bachelor Degree in Software Engineering &nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2016 - Jun. 2020 <br />
          Awarded Honor Graduates of UESTC.
          </p>
        </td>
        </tr>
	  
      </table>





<p></p><p></p><p></p><p></p><p></p>
  
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publication <a href="https://scholar.google.com/citations?user=oAjQIUEAAAAJ" style="font-size:22px;">[Google Scholar]</a></heading>
        </td>
      </tr>
      </table>



<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/sdn/intro.png'  width="160" height="90">
      </td>
      <td valign="top" width="75%">
	 <strong>SDN: Semantic Decoupling Network for Temporal Language Grounding</strong><br>
	 <strong>Xun Jiang</strong>,
	 Xing Xu, Jingran Zhang, Fumin Shen, Zuo Cao, Heng Tao Shen
   <br>
        <em>IEEE Transactions on Neural Networks and Learning Systems, <strong>TNNLS 2022</strong></em><br>
		
		<a href="https://ieeexplore.ieee.org/abstract/document/9925990">[Paperlink]</a>, <a href="https://github.com/CFM-MSG/Code_SDN">[Code]</a><br>
        <em>Area: Video Content Understanding; Cross-modal Retrieval; Multimodal Learning</em> <br>
        <p></p>
      </td>
    </tr>
   </table>
   
   
   <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/dhhn/intro.png'  width="160" height="90">
      </td>
      <td valign="top" width="75%">
	 <strong>DHHN: Dual Hierarchical Hybrid Network for Weakly-Supervised Audio-Visual Video Parsing</strong><br>
	 <strong>Xun Jiang</strong>,
	 Xing Xu,
	 Zhiguo Chen,
 	 Jingran Zhang,    
 	 Jingkuan Song,    
 	 Fumin Shen,    
 	 Huimin Lu,    
 	 Heng Tao Shen,    
   <br>
        <em>ACM Internation Conference on Multimedia, <strong>ACM MM 2022</strong></em><br>
		
		<a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548309">[Paperlink]</a>, <a href="https://github.com/CFM-MSG/Code_DHHN">[Code]</a><br>
        <em>Area: Video Content Understanding, Multimodal Parsing; Audio-Visual Learning</em> <br>
        <p></p>
      </td>
    </tr>
   </table>

   <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/gtlr/intro.png'  width="160" height="90">
      </td>
      <td valign="top" width="75%">
	 <strong>GTLR: Graph-Based Transformer with Language Reconstruction for Video Paragraph Grounding</strong><br>
	 <strong>Xun Jiang</strong>,
	 Xing Xu,
	 Zhiguo Chen,
 	 Jingran Zhang,    
 	 Fumin Shen,    
 	 Zuo Cao,    
 	 Xunliang Cai,    
   <br>
        <em>IEEE International Conference on Multimedia and Expo, <strong>ICME 2022</strong></em><br>
		
		<a href="https://ieeexplore.ieee.org/abstract/document/9859847">[Paperlink]</a>, <a href="https://github.com/CFM-MSG/Code_GTLR">[Code]</a><br>
        <em>Area: Video Content Understanding, Cross-modal Retrieval; Multimodal Learning</em> <br>
        <p></p>
      </td>
    </tr>
   </table>
   

   <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='project/svptr/intro.png'  width="160" height="90">
      </td>
      <td valign="top" width="75%">
	 <strong>Semi-Supervised Video Paragraph Grounding With Contrastive Encoder</strong><br>
	 <strong>Xun Jiang</strong>,
	 Xing Xu,
 	 Jingran Zhang,    
 	 Fumin Shen,    
 	 Zuo Cao,    
 	 Heng Tao Shen,    
   <br>
        <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition, <strong>CVPR 2022</strong></em><br>
		
		<a href="https://ieeexplore.ieee.org/document/9879558">[Paperlink]</a>, <a>[Code]</a><br>
        <em>Area: Video Content Understanding, Weakly-Supervised Learning; Multimodal Learning</em> <br>
        <p></p>
      </td>
    </tr>
   </table>
   



<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Honors & Scholarships</heading>
          <div style="line-height:25px">
          <p>
          <li> <stronghuge>ICME Best Student Paper</stronghuge>,&nbsp; 2022<br/>
          <li> <stronghuge>Academic New Talent of UESTC</stronghuge>,&nbsp; 2022-2023<br/>
          <li>  <stronghuge>UESTC Outstanding Postgraduate Scholarship</stronghuge> ,&nbsp; 2020-2022 <br/>
          <li>  <stronghuge>Honor Graduates of UESTC</stronghuge> ,&nbsp; 2020 <br/>
          <li> <stronghuge>National Encouragement Scholarship</stronghuge> ,&nbsp; 2018-2019<br/>
		      <li> <stronghuge>UESTC Outstanding Undergraduate Scholarship</stronghuge> ,&nbsp; 2017~2019<br/>
          </p>
          </div>
        </td>
      </tr>
</table>



<!-- <p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Project</heading>
		  <p>
		  <div style="text-align: center;">
		  <img src='project/projects_icon.png'  width="600">
		  </p>
          </div>
        </td>
      </tr>
</table> -->



<p></p><p></p><p></p><p></p><p></p>

   
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
			<tbody><tr>
				<td>
				<br>
				<p align="left"><font size="2">
				Last updated on July, 2023
				<p align="middle"><font size="2">
				This template borrowed from <a href="https://github.com/Wangt-CN/Wangt-CN.github.io">Here</a>. Many thanks to Tan Wang. 
				</tbody></table>

</body>
</html>
